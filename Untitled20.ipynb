{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAbuGvbu/dsLrxCQm/CEss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCarlosNas/Classificador-de-nomes-Pytorch/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJQFmqYO4oXZ",
        "outputId": "e734f9e5-20f7-4e3c-f288-ba73d706582a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [2/5 (20%)]/tLoss: 0.963237/tTotal Loss: 1.102410\n",
            "Train Epoch: 1 [4/5 (60%)]/tLoss: 1.138232/tTotal Loss: 1.058150\n",
            "Train Epoch: 2 [2/5 (20%)]/tLoss: 0.505352/tTotal Loss: 0.439180\n",
            "Train Epoch: 2 [4/5 (60%)]/tLoss: 0.686152/tTotal Loss: 0.598190\n",
            "Train Epoch: 3 [2/5 (20%)]/tLoss: 0.063769/tTotal Loss: 0.369520\n",
            "Train Epoch: 3 [4/5 (60%)]/tLoss: 0.112079/tTotal Loss: 0.446530\n",
            "Train Epoch: 4 [2/5 (20%)]/tLoss: 0.483859/tTotal Loss: 0.456490\n",
            "Train Epoch: 4 [4/5 (60%)]/tLoss: 0.160191/tTotal Loss: 0.368880\n",
            "Train Epoch: 5 [2/5 (20%)]/tLoss: 0.008913/tTotal Loss: 0.132250\n",
            "Train Epoch: 5 [4/5 (60%)]/tLoss: 0.079711/tTotal Loss: 0.193110\n",
            "Train Epoch: 6 [2/5 (20%)]/tLoss: 0.111168/tTotal Loss: 0.058710\n",
            "Train Epoch: 6 [4/5 (60%)]/tLoss: 0.034138/tTotal Loss: 0.070600\n",
            "Train Epoch: 7 [2/5 (20%)]/tLoss: 0.010962/tTotal Loss: 0.079220\n",
            "Train Epoch: 7 [4/5 (60%)]/tLoss: 0.034591/tTotal Loss: 0.048970\n",
            "Train Epoch: 8 [2/5 (20%)]/tLoss: 0.027582/tTotal Loss: 0.036230\n",
            "Train Epoch: 8 [4/5 (60%)]/tLoss: 0.010023/tTotal Loss: 0.020880\n",
            "Train Epoch: 9 [2/5 (20%)]/tLoss: 0.006052/tTotal Loss: 0.009420\n",
            "Train Epoch: 9 [4/5 (60%)]/tLoss: 0.016477/tTotal Loss: 0.009040\n",
            "Train Epoch: 10 [2/5 (20%)]/tLoss: 0.004178/tTotal Loss: 0.002550\n",
            "Train Epoch: 10 [4/5 (60%)]/tLoss: 0.003273/tTotal Loss: 0.002490\n",
            "tensor([[-6.6083e-01, -7.2654e-01],\n",
            "        [-5.1954e+00, -5.5573e-03],\n",
            "        [-6.6083e-01, -7.2654e-01],\n",
            "        [-8.1994e-04, -7.1066e+00]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['substantivo', 'verbo', 'substantivo', 'substantivo']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from typing_extensions import Self\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "#dados rotulados\n",
        "x = [\n",
        "    { 'x': 'amar', 'y': 'verbo'},\n",
        "    { 'x': 'André', 'y': 'substantivo'},\n",
        "    {'x': 'beber', 'y': 'verbo'},\n",
        "    {'x': 'Barbara', 'y': 'substantivo'},\n",
        "     { 'x': 'Danilo', 'y': 'substantivo'},\n",
        "    {'x': 'menino', 'y': 'verbo'},\n",
        "     {'x': 'mulher', 'y': 'verbo'},\n",
        "    {'x': 'sorrir', 'y': 'verbo'},\n",
        "    {'x': 'Vivian', 'y': 'substantivo'},\n",
        "    {'x': 'viver', 'y': 'verbo'},\n",
        "     ]\n",
        "\n",
        "#Mapping de classe para indice e indice para classe\n",
        "c2id = {'substantivo': 0, 'verbo': 1}\n",
        "id2c = {0: 'substantivo', 1: 'verbo'}\n",
        "\n",
        "\n",
        "#Mapping de nome paraa indice e indice para nome\n",
        "x2id = { w['x']: i for i, w in enumerate(x) }\n",
        "\n",
        "#criação de um simbolo OOV (out of vocabulary) para nomes fora do conjunto de treinamento\n",
        "x2id ['oov'] = len(x2id)\n",
        "id2x = { i:w for (w, i) in x2id.items()}\n",
        "x2id\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "  def __init__(self, inp_dim, n_classes, x2id):\n",
        "    super(Predictor, self).__init__()\n",
        "    self.x2id = x2id\n",
        "    self.lookup = nn.Embedding (len(x2id), inp_dim)\n",
        "    self.wb = nn.Linear(inp_dim, n_classes)\n",
        "    self.softmax = nn.LogSoftmax(1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    idxs = []\n",
        "    for x in x:\n",
        "      try:\n",
        "        idxs.append(self.x2id[x])\n",
        "      except:\n",
        "        idxs.append(self.x2id['oov'])\n",
        "    idxs = torch.tensor(idxs)\n",
        "    embeddings = self.lookup(idxs)\n",
        "    z = self.wb(embeddings)\n",
        "    return self.softmax(z)\n",
        "\n",
        "#Instanciando o modelo\n",
        "inp_dim = 3\n",
        "n_classes = len(c2id)\n",
        "model = Predictor(inp_dim, n_classes, x2id)\n",
        "\n",
        "\n",
        "#Instanciando função de erro, otimizador e dados em lotes\n",
        "nepochs = 10\n",
        "batch_size = 2\n",
        "batch_status = 2\n",
        "learning_rate = 0.1\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#o DataLoader separa os métodos em lotes\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "traindata = DataLoader(x, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "#Treinamento\n",
        "for epoch in range (nepochs):\n",
        "  losses = []\n",
        "  for batch_idx, row in enumerate (traindata):\n",
        "    x = row ['x']\n",
        "    y = torch.tensor([c2id [c] for  c in row ['y']])\n",
        "\n",
        "    #forward\n",
        "    outputs = model(x)\n",
        "\n",
        "    #calculate loss\n",
        "    loss = criterion(outputs, y)\n",
        "    losses.append (float (loss))\n",
        "\n",
        "    #backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #display\n",
        "    if (batch_idx +1) % batch_status == 0:\n",
        "      print ('Train Epoch: {} [{}/{} ({:.0f}%)]/tLoss: {:.6f}/tTotal Loss: {:6f}'.format(\n",
        "          epoch +1, batch_idx +1, len(traindata),\n",
        "          100. * batch_idx / len(traindata), float(loss),\n",
        "          round(sum(losses) / len(losses), 5)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predição\n",
        "val_x = ['jogar','amar', 'cantar', 'Vivian']\n",
        "\n",
        "outputs = model(val_x)\n",
        "val_y = torch.argmax(outputs,1).tolist()\n",
        "\n",
        "print(outputs)\n",
        "[id2c[c] for c in val_y]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkg0rnScVg2v",
        "outputId": "b0de632e-8ae7-43de-9b18-b5ac2be80755"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-6.6083e-01, -7.2654e-01],\n",
            "        [-5.1954e+00, -5.5573e-03],\n",
            "        [-6.6083e-01, -7.2654e-01],\n",
            "        [-8.1994e-04, -7.1066e+00]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['substantivo', 'verbo', 'substantivo', 'substantivo']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}